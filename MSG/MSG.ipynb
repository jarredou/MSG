{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/interactiveaudiolab/MSG/blob/main/MSG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make it Sound Good (MSG) Music Source Separation Post-Processor\n",
        "\n",
        "Colab demo for the 2022 ISMIR paper **Music Separation Enhancement with Generative Modeling**.\n",
        "\n",
        "[Click here](https://ismir2022program.ismir.net/poster_225.html) to see the abstract, paper, poster, and video.\n",
        "\n",
        "If you use this notebook for research purposes, we kindly ask that you use the following bibtex entry to cite this work:\n",
        "\n",
        "```\n",
        "@inproceedings{schaffer2022music,\n",
        "  title={Music Separation Enhancement with Generative Modeling},\n",
        "  author={Schaffer, Noah and Cogan, Boaz and Manilow, Ethan and Morrison, Max and Seetharaman, Prem and Pardo, Bryan},\n",
        "  booktitle={International Society for Music Information Retrieval (ISMIR)},\n",
        "  month={December},\n",
        "  year={2022}\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "YCeNq2M8-1De"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJssmJTbzjgV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install requirements (run once before using)\n",
        "\n",
        "%%capture\n",
        "!pip install git+https://github.com/nussl/nussl.git@salient_mixsrc2\n",
        "!git clone https://github.com/interactiveaudiolab/MSG.git\n",
        "!pip install -r /content/MSG/requirements.txt\n",
        "!apt-get install sox"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download models (run once before using)\n",
        "\n",
        "import os\n",
        "import urllib.request\n",
        "from pathlib import Path, PurePath\n",
        "\n",
        "\n",
        "def download_models(base_path: Path = '/content/msg_checkpoints'):\n",
        "  \"\"\"Downloads models from HuggingFace and saves them locally.\n",
        "\n",
        "  Args:\n",
        "\n",
        "\n",
        "  Returns:\n",
        "    Dictionary where keys the model names, values are local checkpoint paths.\n",
        "  \"\"\"\n",
        "  model_urls = {\n",
        "      'bass': 'https://huggingface.co/boazcogan/MSG_pretrained_checkpoints/resolve/main/bass29netG.pt',\n",
        "      'drums': 'https://huggingface.co/boazcogan/MSG_pretrained_checkpoints/resolve/main/drums29netG.pt',\n",
        "      'vocals': 'https://huggingface.co/boazcogan/MSG_pretrained_checkpoints/resolve/main/vocals39netG.pt',\n",
        "  }\n",
        "\n",
        "  os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "  model_paths = {}\n",
        "  for i, (nm, url) in enumerate(model_urls.items()):\n",
        "    model_fname = url.split('/')[-1]\n",
        "    out_path = PurePath(base_path, model_fname)\n",
        "    if os.path.isfile(out_path):\n",
        "      print(f'Found {out_path}, skipping download...')\n",
        "    else:\n",
        "      print(f'Downloading {nm:6} model to '\n",
        "            f'{str(out_path)+\",\":41} {i+1} of {len(model_urls)}.')\n",
        "      urllib.request.urlretrieve(url, out_path)\n",
        "    model_paths[nm] = out_path\n",
        "\n",
        "  return model_paths\n",
        "\n",
        "model_paths = download_models()\n"
      ],
      "metadata": {
        "id": "MEbHlDLP1bEk",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run inference\n",
        "\n",
        "from google.colab import files\n",
        "from IPython.display import Audio, display\n",
        "import soundfile as sf\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "file_nm = list(uploaded.keys())[0]\n",
        "in_file_path = PurePath('/content', file_nm)\n",
        "display('Input file:')\n",
        "display(Audio(filename=in_file_path))\n",
        "\n",
        "model = 'vocals' #@param [\"bass\", \"drums\", \"vocals\"]\n",
        "selected_model_path = model_paths[model]\n",
        "\n",
        "display(f'Running MSG inference on {in_file_path}')\n",
        "!python /content/MSG/Run_Inference.py -a $in_file_path -g $selected_model_path\n",
        "\n",
        "out_file_path = PurePath('/content/msg_output', file_nm)\n",
        "\n",
        "display(f'MSG processed file ({out_file_path}):')\n",
        "display(Audio(filename=out_file_path))"
      ],
      "metadata": {
        "id": "3oztnB0r7U-F",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}